{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "15972103",
      "metadata": {},
      "source": [
        "### Loading Packages and Checking Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e5a8cfd",
      "metadata": {
        "id": "9e5a8cfd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image, make_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qxTSQOIlrJR4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxTSQOIlrJR4",
        "outputId": "a6e2cad4-1db6-41e0-98cf-b85dff8c6346"
      },
      "outputs": [],
      "source": [
        "# Using a gpu is adviced since it speeds up training significantly (~3 hours on cpu, but only ~1 hour on gpu)\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffeb0406",
      "metadata": {},
      "source": [
        "### Loading MNIST-Dataset and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f501fdd0",
      "metadata": {
        "id": "f501fdd0"
      },
      "outputs": [],
      "source": [
        "# Normalize our pictures to a range from -1 to 1 since this matches range of Gaussian noise better\n",
        "# We also pad the images so that they work better with the U-Net Pooling.\n",
        "\n",
        "pre_process = transforms.Compose([\n",
        "    transforms.Pad(2),                      # 28x28 â†’ 32x32\n",
        "    transforms.ToTensor(),                  # 0..1\n",
        "    transforms.Normalize((0.5,), (0.5,))    # -1..1\n",
        "])\n",
        "\n",
        "\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=pre_process)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a43e007",
      "metadata": {},
      "source": [
        "### Creating Noise Schedule and Forward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db50f6d2",
      "metadata": {
        "id": "db50f6d2"
      },
      "outputs": [],
      "source": [
        "# Creating the noise schedule\n",
        "T = 1000\n",
        "betas = torch.linspace(0.0002, 0.02, T, device=dev)\n",
        "alphas = 1 - betas\n",
        "alpha_bars = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "# Jumping from x0 directly to xt through explicit noise adding\n",
        "def noising(x0, t, noise):\n",
        "\n",
        "    sqrt_alpha_bars_t = torch.sqrt(alpha_bars[t])[:, None, None, None]\n",
        "    sqrt_one_minus_alpha_bars_t = torch.sqrt(1 - alpha_bars[t])[:, None, None, None]\n",
        "\n",
        "    xt = sqrt_alpha_bars_t * x0 + sqrt_one_minus_alpha_bars_t * noise\n",
        "\n",
        "    return xt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29555d5f",
      "metadata": {},
      "source": [
        "### Neural Network for Noise-Prediction in the Reverse Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BOs8eKspKKge",
      "metadata": {
        "id": "BOs8eKspKKge"
      },
      "outputs": [],
      "source": [
        "# Our model architecture is a standard U-Net. We dont use self attention or residual connections.\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, emb_dim=64):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.time_mlp = nn.Linear(emb_dim, out_ch)\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        x = self.conv(x)\n",
        "        t_emb = self.time_mlp(t)\n",
        "        return x + t_emb[:,:,None,None]\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(Up, self).__init__()\n",
        "        self.up_scale = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up_scale(x1)\n",
        "\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DownLayer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(DownLayer, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "        self.conv = DoubleConv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        a = self.pool(x)\n",
        "        x = self.conv(a, t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpLayer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(UpLayer, self).__init__()\n",
        "        self.up = Up(in_ch, out_ch)\n",
        "        self.conv = DoubleConv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2, t):\n",
        "        a = self.up(x1, x2)\n",
        "        x = self.conv(a, t)\n",
        "        return x\n",
        "\n",
        "# To condition the net on the timestep t, we 'translate' t in the a 'language' the net understands better.\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim=64):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        dev = time.device\n",
        "        half_dim = self.dim//2\n",
        "        factor = torch.log(torch.tensor(10_000, device=dev))/ half_dim\n",
        "        w = torch.exp(-torch.arange(half_dim, device=dev)*factor)\n",
        "        phase_tensor = torch.outer(time, w)\n",
        "\n",
        "        emb = torch.empty(len(time), self.dim, device=dev)\n",
        "        emb[:,0::2] = torch.sin(phase_tensor)\n",
        "        emb[:,1::2] = torch.cos(phase_tensor)\n",
        "        return emb\n",
        "\n",
        "# Final architecture\n",
        "class DenoisingUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenoisingUNet, self).__init__()\n",
        "\n",
        "        self.t_embedding = SinusoidalPositionEmbeddings()\n",
        "\n",
        "        self.conv1 = DoubleConv(1, 64)\n",
        "        self.down1 = DownLayer(64, 128)\n",
        "        self.down2 = DownLayer(128, 256)\n",
        "        self.down3 = DownLayer(256, 512)\n",
        "        self.up1 = UpLayer(512, 256)\n",
        "        self.up2 = UpLayer(256, 128)\n",
        "        self.up3 = UpLayer(128, 64)\n",
        "        self.last_conv = nn.Conv2d(64, 1, 1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t = self.t_embedding(t)\n",
        "        x1 = self.conv1(x, t)\n",
        "        x2 = self.down1(x1, t)\n",
        "        x3 = self.down2(x2, t)\n",
        "        x4 = self.down3(x3, t)\n",
        "        x1_up = self.up1(x4, x3, t)\n",
        "        x2_up = self.up2(x1_up, x2, t)\n",
        "        x3_up = self.up3(x2_up, x1, t)\n",
        "        output = self.last_conv(x3_up)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cb71780",
      "metadata": {},
      "source": [
        "### Sampling Procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "836f913c",
      "metadata": {
        "id": "836f913c"
      },
      "outputs": [],
      "source": [
        "# Sampling function to generate images\n",
        "def sample(n=64):\n",
        "    xt = torch.randn(n,1,32,32, device=dev)\n",
        "    for t in reversed(range(0,T)):\n",
        "        t_tensor = torch.full((n,), t, dtype=torch.long, device=dev)\n",
        "        with torch.no_grad():\n",
        "          eps_pred = model(xt, t_tensor)\n",
        "\n",
        "        z = torch.randn_like(xt) if t > 0 else torch.zeros_like(xt)\n",
        "\n",
        "        xt = 1/torch.sqrt(alphas[t]) * (xt - (1-alphas[t])/torch.sqrt(1-alpha_bars[t]) * eps_pred) + torch.sqrt(betas[t]) * z\n",
        "    return xt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a45549fe",
      "metadata": {},
      "source": [
        "### Plotting Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "743f1827",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_samples(x0, title='Samples', save=True):\n",
        "    samples = x0.detach().cpu()\n",
        "    samples = (samples + 1) / 2  # Rescale to [0, 1]\n",
        "    samples = samples.clamp(0, 1)\n",
        "\n",
        "    grid = make_grid(samples)\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    if save==True:\n",
        "        plt.savefig(f\"media/{title}.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d26481",
      "metadata": {},
      "source": [
        "### Training Loop with Performance Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce203874",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "ce203874",
        "outputId": "032a7a80-ac3c-47e6-bf79-b241897a01dd"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "model = DenoisingUNet().to(dev)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "epochs=100\n",
        "\n",
        "# Training loop (takes about 1 hour to finish)\n",
        "for epoch in range(epochs):\n",
        "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "    epoch_loss=0\n",
        "    for b in pbar:\n",
        "        x0 = b[0].to(dev)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        t = torch.randint(0, T, (x0.shape[0],), device=dev)\n",
        "\n",
        "        eps = torch.randn_like(x0)\n",
        "        xt = noising(x0, t, eps)\n",
        "\n",
        "        eps_pred = model(xt, t)\n",
        "\n",
        "        loss = loss_fn(eps_pred, eps)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        pbar.set_postfix(epoch_loss=epoch_loss)\n",
        "\n",
        "    # Plotting the samples every 10th epoch to see learning progression\n",
        "    if (epoch+1)%10==0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x0_pred = sample(n=8)\n",
        "            plot_samples(x0_pred, title=f\"Samples at Epoch: {epoch+1}\", save=False)\n",
        "        model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7489d9",
      "metadata": {},
      "source": [
        "### Generating Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "szyhJ9Mu2nZ1",
      "metadata": {
        "collapsed": true,
        "id": "szyhJ9Mu2nZ1"
      },
      "outputs": [],
      "source": [
        "# Sample pictures from our model and plot them. \n",
        "model.eval()\n",
        "x0_pred = sample()\n",
        "plot_samples(x0_pred, title=\"Generated Samples\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
